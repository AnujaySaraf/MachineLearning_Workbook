{
    "nbformat_minor": 1, 
    "cells": [
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "#  Download the required Dataset for analysis\n# ! wget http://stat-computing.org/dataexpo/2009/2007.csv.bz2\n# ! http://stat-computing.org/dataexpo/2009/2008.csv.bz2\n# ! wget https://github.com/jayyanar/MachineLearning_Workbook/blob/master/2007-ord-weather-data.csv --no-check-certificate\n# ! wget https://github.com/jayyanar/MachineLearning_Workbook/blob/master/2008-ord-weather-data.csv --no-check-certificate\n# ! bzip2 -d 2007.csv.bz2\n# ! bzip2 -d 2008.csv.bz2"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "! ls -lrt\n"
        }, 
        {
            "execution_count": 44, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# For SQL-type queries (Spark)\nfrom pyspark.sql import SQLContext\nfrom pyspark.sql.types import *\nfrom pyspark.sql import Row\nfrom pyspark.sql.functions import udf, col, asc, desc\n\n# For regression and other possible ML tools (Spark)\nfrom pyspark.mllib.regression import LabeledPoint\nfrom pyspark.mllib.linalg import Vectors\nfrom pyspark.ml.classification import LogisticRegression\nfrom pyspark.ml.param import Param, Params\nfrom pyspark.mllib.classification import LogisticRegressionWithLBFGS, LogisticRegressionModel\nfrom pyspark.mllib.regression import LabeledPoint\nfrom pyspark.mllib.stat import Statistics\n\n# Important for managing features  (Spark)\nfrom pyspark.ml.feature import OneHotEncoder, StringIndexer\nfrom pyspark.ml.feature import VectorAssembler\n\n# For displaying and other related IPython tools...\nfrom IPython.display import display\nfrom IPython.html.widgets import interact\n\n# Typycal Python tools\nimport sys\nimport numpy as np\nimport pandas as pd\nimport time\nimport datetime\nimport matplotlib.pyplot as plt\nimport os.path"
        }, 
        {
            "execution_count": 2, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# To show plots inline\nget_ipython().magic(u'matplotlib inline')"
        }, 
        {
            "source": "# function to read HDFS file into dataframe using PyDoop\nimport pydoop.hdfs as hdfs\ndef read_csv_from_hdfs(path, cols, col_types=None):\n  files = hdfs.ls(path);\n  pieces = []\n  for f in files:\n    fhandle = hdfs.open(f)\n    pieces.append(pd.read_csv(fhandle, names=cols, dtype=col_types))\n    fhandle.close()\n  return pd.concat(pieces, ignore_index=True)", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "# read 2007 year file\ncols = ['year', 'month', 'day', 'dow', 'DepTime', 'CRSDepTime', 'ArrTime', 'CRSArrTime', 'Carrier', 'FlightNum', \n        'TailNum', 'ActualElapsedTime', 'CRSElapsedTime', 'AirTime', 'ArrDelay', 'DepDelay', 'Origin', 'Dest', \n        'Distance', 'TaxiIn', 'TaxiOut', 'Cancelled', 'CancellationCode', 'Diverted', 'CarrierDelay', \n        'WeatherDelay', 'NASDelay', 'SecurityDelay', 'LateAircraftDelay'];\nflt_2007 = read_csv_from_hdfs('airline/delay/2007.csv', cols)\n\nflt_2007.shape", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 3, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "textFile = sc.textFile('2007.csv')"
        }, 
        {
            "execution_count": 4, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "textFileRDD = textFile.map(lambda x: x.split(','))\nheader = textFileRDD.first()\n\ntextRDD = textFileRDD.filter(lambda r: r != header)"
        }, 
        {
            "execution_count": 5, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Number of records  7453216\n"
                }
            ], 
            "source": "num_records = textFileRDD.count()\nprint ('Number of records ' , num_records)"
        }, 
        {
            "execution_count": 6, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "aux_ = textFileRDD.take(2)\nfeature_names = aux_[0]\nfeature_example = aux_[1]"
        }, 
        {
            "execution_count": 7, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Feature Names  ['Year', 'Month', 'DayofMonth', 'DayOfWeek', 'DepTime', 'CRSDepTime', 'ArrTime', 'CRSArrTime', 'UniqueCarrier', 'FlightNum', 'TailNum', 'ActualElapsedTime', 'CRSElapsedTime', 'AirTime', 'ArrDelay', 'DepDelay', 'Origin', 'Dest', 'Distance', 'TaxiIn', 'TaxiOut', 'Cancelled', 'CancellationCode', 'Diverted', 'CarrierDelay', 'WeatherDelay', 'NASDelay', 'SecurityDelay', 'LateAircraftDelay']\n"
                }
            ], 
            "source": "print ('Feature Names ' , feature_names)"
        }, 
        {
            "execution_count": 8, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Feature Example  ['2007', '1', '1', '1', '1232', '1225', '1341', '1340', 'WN', '2891', 'N351', '69', '75', '54', '1', '7', 'SMF', 'ONT', '389', '4', '11', '0', '', '0', '0', '0', '0', '0', '0']\n"
                }
            ], 
            "source": "print ('Feature Example ' , feature_example)"
        }, 
        {
            "execution_count": 9, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Number of features =  29\n"
                }
            ], 
            "source": "print (\"Number of features = \" , len(feature_example))"
        }, 
        {
            "execution_count": 10, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "<class 'list'>\n"
                }
            ], 
            "source": "print (type(feature_example))"
        }, 
        {
            "execution_count": 11, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# ### Creating a SQL Dataframe from RDD\n# \n# We now create a SQL DataFrame, this entity is a distributed collection of data organized into named columns. It is conceptually equivalent to a table in a relational database or a data frame in Python, but with richer optimizations under the hood. We will utilize the recently created Spark RDD and use the Spark SQL context to create the desired data frame,\n\n# We first create function that will allow to parse a record of our RDD into the desired format. As a reference we take a look at features_names and feature_example we just created above\n\n\n\ndef parse(r):\n    try:\n        x=Row(Year=int(r[0]),\\\n          Month=int(r[1]),\\\n          DayofMonth=int(r[2]),\\\n          DayOfWeek=int(r[3]),\\\n          DepTime=int(float(r[4])), \\\n          CRSDepTime=int(r[5]),\\\n          ArrTime=int(float(r[6])),\\\n          CRSArrTime=int(r[7]), \\\n          UniqueCarrier=r[8],\\\n          DepDelay=int(float(r[15])),\\\n          Origin=r[16],\\\n          Dest=r[17], \\\n          Distance=int(float(r[18])),\\\n          CarrierDelay=int(float(r[24])),\\\n          WeatherDelay=int(float(r[25])),\\\n          NASDelay= int(float(r[26])),\\\n          SecurityDelay=int(float(r[27])),\\\n          LateAircraftDelay=int(float(r[28])))  \n    except:\n        x=None  \n    return x\n\nrowRDD = textRDD.map(lambda r: parse(r)).filter(lambda r:r != None)\nairline_df = sqlContext.createDataFrame(rowRDD)"
        }, 
        {
            "execution_count": 15, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# We add a new column to our data frame, **DepDelayed**, a binary variable:\n# - **True**, for flights that have > 15 minutes of delay\n# - **False**, for flights that have <= 15 minutes of delay\n# \n# We will later use **Depdelayed** as the target/label column in the classification process.\n\n\n#airline_df = airline_df.withColumn('DepDelayed', airline_df['DepDelay']>15)\n#airline_df = airline_df.withColumn('DepDelayed',airline_df['Origin']==\"ORD\")\n#airline_df_ORD = airline_df.withColumn('DepDelayed', airline_df.filter((col(\"Origin\") == \"ORD\") | (col(\"DepDelay\")>15)))\nairline_df_ORD = airline_df.filter((col(\"Origin\") == \"ORD\"))\nairline_df_ORD_15 = airline_df_ORD.withColumn('DepDelayed', airline_df_ORD['DepDelay']>15)"
        }, 
        {
            "execution_count": 16, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 16, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "[Row(ArrTime=1359, CRSArrTime=1414, CRSDepTime=1100, CarrierDelay=0, DayOfWeek=4, DayofMonth=25, DepDelay=-8, DepTime=1052, Dest='EWR', Distance=719, LateAircraftDelay=0, Month=1, NASDelay=0, Origin='ORD', SecurityDelay=0, UniqueCarrier='XE', WeatherDelay=0, Year=2007, DepDelayed=False),\n Row(ArrTime=1811, CRSArrTime=1750, CRSDepTime=1500, CarrierDelay=0, DayOfWeek=7, DayofMonth=28, DepDelay=41, DepTime=1541, Dest='IAH', Distance=925, LateAircraftDelay=16, Month=1, NASDelay=5, Origin='ORD', SecurityDelay=0, UniqueCarrier='XE', WeatherDelay=0, Year=2007, DepDelayed=True),\n Row(ArrTime=2305, CRSArrTime=2211, CRSDepTime=2000, CarrierDelay=0, DayOfWeek=1, DayofMonth=29, DepDelay=45, DepTime=2045, Dest='CLE', Distance=316, LateAircraftDelay=45, Month=1, NASDelay=9, Origin='ORD', SecurityDelay=0, UniqueCarrier='XE', WeatherDelay=0, Year=2007, DepDelayed=True),\n Row(ArrTime=2204, CRSArrTime=2220, CRSDepTime=1900, CarrierDelay=0, DayOfWeek=3, DayofMonth=17, DepDelay=-9, DepTime=1851, Dest='EWR', Distance=719, LateAircraftDelay=0, Month=1, NASDelay=0, Origin='ORD', SecurityDelay=0, UniqueCarrier='XE', WeatherDelay=0, Year=2007, DepDelayed=False),\n Row(ArrTime=2256, CRSArrTime=2003, CRSDepTime=1745, CarrierDelay=0, DayOfWeek=5, DayofMonth=12, DepDelay=180, DepTime=2045, Dest='CLE', Distance=316, LateAircraftDelay=173, Month=1, NASDelay=0, Origin='ORD', SecurityDelay=0, UniqueCarrier='XE', WeatherDelay=0, Year=2007, DepDelayed=True),\n Row(ArrTime=1247, CRSArrTime=1212, CRSDepTime=930, CarrierDelay=0, DayOfWeek=5, DayofMonth=12, DepDelay=29, DepTime=959, Dest='IAH', Distance=925, LateAircraftDelay=29, Month=1, NASDelay=6, Origin='ORD', SecurityDelay=0, UniqueCarrier='XE', WeatherDelay=0, Year=2007, DepDelayed=True),\n Row(ArrTime=2242, CRSArrTime=2211, CRSDepTime=2000, CarrierDelay=0, DayOfWeek=5, DayofMonth=26, DepDelay=35, DepTime=2035, Dest='CLE', Distance=316, LateAircraftDelay=31, Month=1, NASDelay=0, Origin='ORD', SecurityDelay=0, UniqueCarrier='XE', WeatherDelay=0, Year=2007, DepDelayed=True),\n Row(ArrTime=1535, CRSArrTime=1547, CRSDepTime=1325, CarrierDelay=0, DayOfWeek=2, DayofMonth=2, DepDelay=-1, DepTime=1324, Dest='CLE', Distance=316, LateAircraftDelay=0, Month=1, NASDelay=0, Origin='ORD', SecurityDelay=0, UniqueCarrier='XE', WeatherDelay=0, Year=2007, DepDelayed=False),\n Row(ArrTime=1910, CRSArrTime=1914, CRSDepTime=1600, CarrierDelay=0, DayOfWeek=7, DayofMonth=28, DepDelay=9, DepTime=1609, Dest='EWR', Distance=719, LateAircraftDelay=0, Month=1, NASDelay=0, Origin='ORD', SecurityDelay=0, UniqueCarrier='XE', WeatherDelay=0, Year=2007, DepDelayed=False),\n Row(ArrTime=1716, CRSArrTime=1609, CRSDepTime=1255, CarrierDelay=0, DayOfWeek=2, DayofMonth=9, DepDelay=-2, DepTime=1253, Dest='EWR', Distance=719, LateAircraftDelay=0, Month=1, NASDelay=67, Origin='ORD', SecurityDelay=0, UniqueCarrier='XE', WeatherDelay=0, Year=2007, DepDelayed=False)]"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "airline_df_ORD_15.take(10)"
        }, 
        {
            "execution_count": 28, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Total flights Origin at ORD Chicago Airport: 358462\n+----------+------+\n|DepDelayed| count|\n+----------+------+\n|      true|105807|\n|     false|252655|\n+----------+------+\n\nNone\n"
                }
            ], 
            "source": "print (\"Total flights Origin at ORD Chicago Airport: \" + str(airline_df_ORD_15.count()))\nprint (airline_df_ORD_15.groupby('DepDelayed').count().show())"
        }, 
        {
            "execution_count": 50, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "+-----+-----+\n|Month|count|\n+-----+-----+\n|    1| 9783|\n|    2|11002|\n|    3|10074|\n|    4| 8597|\n|    5| 6716|\n|    6| 9173|\n|    7| 8375|\n|    8|10039|\n|    9| 5997|\n|   10| 6826|\n|   11| 6830|\n|   12|12395|\n+-----+-----+\n\n"
                }
            ], 
            "source": "#airline_df_ORD_15.take(10)\nairline_df_ORD_15.filter(airline_df_ORD_15.DepDelayed == True).groupby(airline_df_ORD_15.Month).count().sort(asc(\"Month\")).show()"
        }, 
        {
            "execution_count": 54, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "ename": "TypeError", 
                    "evalue": "'Column' object is not callable", 
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m", 
                        "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)", 
                        "\u001b[0;32m<ipython-input-54-0f9e905a6eb4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mairline_df_ORD_15\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwithColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Hour'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mairline_df_ORD_15\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCRSDepTime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhour\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'timestamp'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m", 
                        "\u001b[0;31mTypeError\u001b[0m: 'Column' object is not callable"
                    ], 
                    "output_type": "error"
                }
            ], 
            "source": "airline_df_ORD_15.withColumn('Hour', airline_df_ORD_15.CRSDepTime.hour('timestamp')).show()"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# define hour function to obtain hour of day\ndef hour_ex(x): \n    h = int(str(int(x)).zfill(4)[:2])\n    return h\n\n# register as a UDF \nf = udf(hour_ex, IntegerType())\n\n#CRSDepTime: scheduled departure time (local, hhmm)\nairline_df = airline_df.withColumn('hour', f(airline_df.CRSDepTime))\nairline_df.registerTempTable(\"airlineDF\")"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "#Exploration: What are the primary causes for flight delays\ncause_delay = sqlContext.sql(\"SELECT sum(WeatherDelay) Weather,sum(NASDelay) NAS,sum(SecurityDelay) Security,sum(LateAircraftDelay) lateAircraft,sum(CarrierDelay) Carrier FROM airlineDF \")\ndf_cause_delay = cause_delay.toPandas()\ndf_cause_delay.head()"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "#Exploration: Which Airports have the Most Delays\ngroupedDelay = sqlContext.sql(\"SELECT Origin, count(*) conFlight,avg(DepDelay) delay \\\n                                FROM airlineDF \\\n                                GROUP BY Origin\")\ndf_origin = groupedDelay.toPandas()\ndf_origin.head()\n"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "df_origin.sort_values('delay',ascending=0).head()"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "! ls -lrta"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "#o map each Airport to corresponding Long and Lat,load the dataset needed\n\n\n#df = pd.read_csv('airports.dat', index_col=0, names = ['name', 'city', 'country','IATA','ICAO','lat','lng','alt','TZone','DST','Tz'], header=0)\n#df = pd.read_csv('airports.dat', header=0, names = ['name', 'city', 'country','IATA','ICAO','lat','lng','alt','TZone','DST','Tz'])\ndf1= pd.read_csv('airports.dat',header=0, names = ['name', 'city', 'country','IATA','ICAO','lat','lng','alt','TZone','DST','Tz'])\n#df = pd.read_csv('airports.dat', index_col=0,names = ['name', 'city', 'country','IATA','ICAO','lat','lng','alt','TZone','DST','Tz'], header=0)\ndf1.head()"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "df_airports = pd.merge(df_origin, df, left_on = 'Origin', right_on = 'IATA')\ndf_airports.head()"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "df_airports.sort_values('delay',ascending=0).head(10)"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "def sigmoid(x):\n    return 1 / (1 + np.exp(-x))\n\ndef zscore(x):\n    return (x-np.average(x))/np.std(x)"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "! conda create -n my_DSX-Python35-Spark --clone=\"/usr/local/src/conda3_runtime/home/envs/DSX-Python35-Spark\"\n! conda install -c conda-forge basemap-data-hires=1.0.8.dev0 -y"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "from mpl_toolkits.basemap import Basemap\nimport matplotlib.pyplot as plt\nfrom pylab import rcParams\n%matplotlib inline\n\nrcParams['figure.figsize'] = (14,10)\n\n\nmy_map = Basemap(projection='merc',\n            resolution = 'l', area_thresh = 1000.0,\n            llcrnrlon=-130, llcrnrlat=22, #min longitude (llcrnrlon) and latitude (llcrnrlat)\n            urcrnrlon=-60, urcrnrlat=50) #max longitude (urcrnrlon) and latitude (urcrnrlat)\n\nmy_map.drawcoastlines()\nmy_map.drawcountries()\nmy_map.drawmapboundary()\nmy_map.fillcontinents(color = 'white', alpha = 0.3)\nmy_map.shadedrelief()\n\n# To create a color map\ncolors = plt.get_cmap('hot')(np.linspace(0.0, 1.0, 30))\ncolors=np.flipud(colors)\n\n#----- Scatter -------\ncountrange=max(df_airports['conFlight'])-min(df_airports['conFlight'])\nal=np.array([sigmoid(x) for x in zscore(df_airports['delay'])])\nxs,ys = my_map(np.asarray(df_airports['lng']), np.asarray(df_airports['lat']))\nval=df_airports['conFlight']*4000.0/countrange\n\nmy_map.scatter(xs, ys,  marker='o', s= val, alpha = 0.8,color=colors[(al*20).astype(int)])\n\n#----- Text -------\ndf_text=df_airports[(df_airports['conFlight']>60000) & (df_airports['IATA'] != 'HNL')]\nxt,yt = my_map(np.asarray(df_text['lng']), np.asarray(df_text['lat']))\ntxt=np.asarray(df_text['IATA'])\nzp=zip(xt,yt,txt)\nfor row in zp:\n    #print zp[2]\n    plt.text(row[0],row[1],row[2], fontsize=10, color='blue',)\n\nprint(\"Each marker is an airport.\")\nprint(\"Size of markers: Airport Traffic (larger means higher number of flights in year)\")\nprint(\"Color of markers: Average Flight Delay (Redder means longer delays)\")\n\nplt.show()"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "\n#Exploration: Route delay\n#Which Routes are typically the most delayed?\ngrp_rout_Delay = sqlContext.sql(\"SELECT Origin, Dest, count(*) traffic,avg(Distance) avgDist,\\\n                                    avg(DepDelay) avgDelay\\\n                                FROM airlineDF \\\n                                GROUP BY Origin,Dest\")\nrout_Delay = grp_rout_Delay.toPandas()"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "df_airport_rout1 = pd.merge(rout_Delay, df, left_on = 'Origin', right_on = 'IATA')\ndf_airport_rout2 = pd.merge(df_airport_rout1, df, left_on = 'Dest', right_on = 'IATA')\ndf_airport_rout = df_airport_rout2[[\"Origin\",\"lat_x\",\"lng_x\",\"Dest\",\"lat_y\",\"lng_y\",\\\n                                    \"avgDelay\", \"traffic\"]]"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "df_airport_rout.sort('avgDelay',ascending=0).head()"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "rcParams['figure.figsize'] = (14,10)\n\n\nmy_map = Basemap(projection='merc',\n            resolution = 'l', area_thresh = 1000.0,\n            llcrnrlon=-130, llcrnrlat=22, #min longitude (llcrnrlon) and latitude (llcrnrlat)\n            urcrnrlon=-60, urcrnrlat=50) #max longitude (urcrnrlon) and latitude (urcrnrlat)\n\nmy_map.drawcoastlines()\nmy_map.drawcountries()\nmy_map.drawmapboundary()\nmy_map.fillcontinents(color = 'white', alpha = 0.3)\nmy_map.shadedrelief()\n\ndelay=np.array([sigmoid(x) for x in zscore(df_airports[\"delay\"])])\ncolors = plt.get_cmap('hot')(np.linspace(0.0, 1.0, 40))\ncolors=np.flipud(colors)\nxs,ys = my_map(np.asarray(df_airports['lng']), np.asarray(df_airports['lat']))\nxo,yo = my_map(np.asarray(df_airport_rout['lng_x']), np.asarray(df_airport_rout['lat_x']))\nxd,yd = my_map(np.asarray(df_airport_rout['lng_y']), np.asarray(df_airport_rout['lat_y']))\n\nmy_map.scatter(xs, ys,  marker='o',  alpha = 0.8,color=colors[(delay*20).astype(int)])\n\n\nal=np.array([sigmoid(x) for x in zscore(df_airport_rout[\"avgDelay\"])])\nf=zip(xo,yo,xd,yd,df_airport_rout['avgDelay'],al)\nfor row in f:\n    plt.plot([row[0],row[2]], [row[1],row[3]],'-',alpha=0.07, \\\n             color=colors[(row[5]*30).astype(int)] )\n    \n\nfor row in zp:\n    plt.text(row[0],row[1],row[2], fontsize=10, color='blue',)\n\nprint(\"Each line represents a route from the Origin to Destination airport.\")\nprint(\"The redder line, the higher probablity of delay.\")\n    \nplt.show()"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "#Exploration: Airport Origin delay per month\nOrigin_Airport=\"SJC\""
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "df_ORG = sqlContext.sql(\"SELECT * from airlineDF WHERE origin='\"+ Origin_Airport+\"'\")\ndf_ORG.registerTempTable(\"df_ORG\")\ndf_ORG.select('ArrTime','CRSArrTime','CRSDepTime',\\\n              'DayOfWeek','DayofMonth','DepDelay','DepTime','Dest').show(2)"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "print (\"total flights from this ariport: \" + str(df_ORG.count()))"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "grp_carr = sqlContext.sql(\"SELECT  UniqueCarrier,month, avg(DepDelay) avgDelay from df_ORG \\\n                            WHERE DepDelayed=True \\\n                            GROUP BY UniqueCarrier,month\")\ns = grp_carr.toPandas()"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "ps = s.pivot(index='month', columns='UniqueCarrier', values='avgDelay')[['AA','UA','US']]"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "rcParams['figure.figsize'] = (8,5)\nps.plot(kind='bar', colormap='Greens');\nplt.xlabel('Average delay')\nplt.ylabel('Month')\nplt.title('How much delay does each carrier has in each month?')"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "\n#We see that average delay in this year is is highest in November and October in this airport.\n#Exploration: Airport Origin delay per day/hour\nhour_grouped = df_ORG.filter(df_ORG['DepDelayed']).select('DayOfWeek','hour','DepDelay').groupby('DayOfWeek','hour').mean('DepDelay')"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "#Modeling: Logistic Regression\ndf_model=df_ORG\nstringIndexer1 = StringIndexer(inputCol=\"Origin\", outputCol=\"originIndex\")\nmodel_stringIndexer = stringIndexer1.fit(df_model)\nindexedOrigin = model_stringIndexer.transform(df_model)\nencoder1 = OneHotEncoder(dropLast=False, inputCol=\"originIndex\", outputCol=\"originVec\")\ndf_model = encoder1.transform(indexedOrigin)"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "assembler = VectorAssembler(\n    inputCols = ['Year','Month','DayofMonth','DayOfWeek','hour','Distance','originVec'],\n    outputCol = \"features\")\noutput = assembler.transform(df_model)\nairlineRDD=output.map(lambda row: LabeledPoint([0,1][row['DepDelayed']],row['features']))"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "#  Spliting dataset into train and test dtasets\ntrainRDD,testRDD=airlineRDD.randomSplit([0.7,0.3])"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# Build the model\nmodel = LogisticRegressionWithLBFGS.train(trainRDD)"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "#Model Evaluation\n# Evaluating the model on testing data\nlabelsAndPreds = testRDD.map(lambda p: (p.label, model.predict(p.features)))"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "def conf(r):\n    if r[0] == r[1] ==1: x= 'TP'\n    if r[0] == r[1] ==0: x= 'TN'\n    if r[0] == 1 and  r[1] ==0: x= 'FN'\n    if r[0] == 0 and  r[1] ==1: x= 'FP'\n    return (x)\nacc1 = labelsAndPreds.map(lambda (v, p): ((v, p),1)).reduceByKey(lambda a, b: a + b).take(5)\nacc = [(conf(x[0]),x[1]) for x in acc1]"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "TP=TN=FP=FN=0.0\nfor x in acc: \n    if x[0]=='TP': TP= x[1]\n    if x[0]=='TN': TN= x[1]\n    if x[0]=='FP': FP= x[1]\n    if x[0]=='FN': FN= x[1]\neps = sys.float_info.epsilon\nAccuracy = (TP+TN) / (TP + TN+ FP+FN+eps) \nprint (\"Model Accuracy for JFK: %1.2f %%\" % (Accuracy*100))"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": ""
        }
    ], 
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.5 with Spark 2.1", 
            "name": "python3-spark21", 
            "language": "python"
        }, 
        "language_info": {
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "version": "3.5.4", 
            "name": "python", 
            "file_extension": ".py", 
            "pygments_lexer": "ipython3", 
            "codemirror_mode": {
                "version": 3, 
                "name": "ipython"
            }
        }
    }, 
    "nbformat": 4
}