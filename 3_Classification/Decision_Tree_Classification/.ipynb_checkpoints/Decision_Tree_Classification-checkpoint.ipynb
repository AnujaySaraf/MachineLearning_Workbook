{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#  Decision Tree Classification (category Variable)\n",
    "\n",
    "# Information Entrophy - Head|Tail - Probability\n",
    "#https://www.khanacademy.org/computing/computer-science/informationtheory/moderninfotheory/v/information-entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jayyanar\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Import Libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Purchased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15624510</td>\n",
       "      <td>Male</td>\n",
       "      <td>19</td>\n",
       "      <td>19000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15810944</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>20000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15668575</td>\n",
       "      <td>Female</td>\n",
       "      <td>26</td>\n",
       "      <td>43000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15603246</td>\n",
       "      <td>Female</td>\n",
       "      <td>27</td>\n",
       "      <td>57000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15804002</td>\n",
       "      <td>Male</td>\n",
       "      <td>19</td>\n",
       "      <td>76000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    User ID  Gender  Age  EstimatedSalary  Purchased\n",
       "0  15624510    Male   19            19000          0\n",
       "1  15810944    Male   35            20000          0\n",
       "2  15668575  Female   26            43000          0\n",
       "3  15603246  Female   27            57000          0\n",
       "4  15804002    Male   19            76000          0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('Social_Network_Ads.csv')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 5)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identify the shape of the dataset\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 400 entries, 0 to 399\n",
      "Data columns (total 5 columns):\n",
      "User ID            400 non-null int64\n",
      "Gender             400 non-null object\n",
      "Age                400 non-null int64\n",
      "EstimatedSalary    400 non-null int64\n",
      "Purchased          400 non-null int64\n",
      "dtypes: int64(4), object(1)\n",
      "memory usage: 15.7+ KB\n"
     ]
    }
   ],
   "source": [
    "# Identify the shape of the dataset\n",
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set the Independent Variable (X) and dependent variable (y) = f(x)=y\n",
    "## Make sure always X is matrix and Y is vector\n",
    "X = dataset.iloc[:,[2,3]].values\n",
    "y = dataset.iloc[:,4].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split the dataset into Training set and Testing Set\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X, y, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling is not needed if we not based on Euclidean DIstance , Since Decision Tree use Mahattan \n",
    "# We dont want to reduce the scale\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_x = StandardScaler()\n",
    "X_train = sc_x.fit_transform(X_train)\n",
    "X_test = sc_x.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=42,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting SVM regression to the training set\n",
    "# Test  with different Kernel -- \"linear' , 'rbf', 'poly'\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "classifier = DecisionTreeClassifier(criterion='entropy', random_state = 42)\n",
    "classifier.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[    30,  87000],\n",
       "        [    38,  50000],\n",
       "        [    35,  75000],\n",
       "        [    30,  79000],\n",
       "        [    35,  50000],\n",
       "        [    27,  20000],\n",
       "        [    31,  15000],\n",
       "        [    36, 144000],\n",
       "        [    18,  68000],\n",
       "        [    47,  43000],\n",
       "        [    30,  49000],\n",
       "        [    28,  55000],\n",
       "        [    37,  55000],\n",
       "        [    39,  77000],\n",
       "        [    20,  86000],\n",
       "        [    32, 117000],\n",
       "        [    37,  77000],\n",
       "        [    19,  85000],\n",
       "        [    55, 130000],\n",
       "        [    35,  22000],\n",
       "        [    35,  47000],\n",
       "        [    47, 144000],\n",
       "        [    41,  51000],\n",
       "        [    47, 105000],\n",
       "        [    23,  28000],\n",
       "        [    49, 141000],\n",
       "        [    28,  87000],\n",
       "        [    29,  80000],\n",
       "        [    37,  62000],\n",
       "        [    32,  86000],\n",
       "        [    21,  88000],\n",
       "        [    37,  79000],\n",
       "        [    57,  60000],\n",
       "        [    37,  53000],\n",
       "        [    24,  58000],\n",
       "        [    18,  52000],\n",
       "        [    22,  81000],\n",
       "        [    34,  43000],\n",
       "        [    31,  34000],\n",
       "        [    49,  36000],\n",
       "        [    27,  88000],\n",
       "        [    41,  52000],\n",
       "        [    27,  84000],\n",
       "        [    35,  20000],\n",
       "        [    43, 112000],\n",
       "        [    27,  58000],\n",
       "        [    37,  80000],\n",
       "        [    52,  90000],\n",
       "        [    26,  30000],\n",
       "        [    49,  86000],\n",
       "        [    57, 122000],\n",
       "        [    34,  25000],\n",
       "        [    35,  57000],\n",
       "        [    34, 115000],\n",
       "        [    59,  88000],\n",
       "        [    45,  32000],\n",
       "        [    29,  83000],\n",
       "        [    26,  80000],\n",
       "        [    49,  28000],\n",
       "        [    23,  20000],\n",
       "        [    32,  18000],\n",
       "        [    60,  42000],\n",
       "        [    19,  76000],\n",
       "        [    36,  99000],\n",
       "        [    19,  26000],\n",
       "        [    60,  83000],\n",
       "        [    24,  89000],\n",
       "        [    27,  58000],\n",
       "        [    40,  47000],\n",
       "        [    42,  70000],\n",
       "        [    32, 150000],\n",
       "        [    35,  77000],\n",
       "        [    22,  63000],\n",
       "        [    45,  22000],\n",
       "        [    27,  89000],\n",
       "        [    18,  82000],\n",
       "        [    42,  79000],\n",
       "        [    40,  60000],\n",
       "        [    53,  34000],\n",
       "        [    47, 107000],\n",
       "        [    58, 144000],\n",
       "        [    59,  83000],\n",
       "        [    24,  55000],\n",
       "        [    26,  35000],\n",
       "        [    58,  38000],\n",
       "        [    42,  80000],\n",
       "        [    40,  75000],\n",
       "        [    59, 130000],\n",
       "        [    46,  41000],\n",
       "        [    41,  60000],\n",
       "        [    42,  64000],\n",
       "        [    37, 146000],\n",
       "        [    23,  48000],\n",
       "        [    25,  33000],\n",
       "        [    24,  84000],\n",
       "        [    27,  96000],\n",
       "        [    23,  63000],\n",
       "        [    48,  33000],\n",
       "        [    48,  90000],\n",
       "        [    42, 104000]], dtype=int64),\n",
       " array([0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
       "        1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
       "        0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0,\n",
       "        0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1,\n",
       "        0, 0, 0, 1, 0, 1, 1, 1], dtype=int64))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
       "       0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0,\n",
       "       1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1,\n",
       "       0, 0, 0, 1, 0, 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Predict the test_set results\n",
    "y_predict = classifier.predict(X_test)\n",
    "y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[62,  6],\n",
       "       [ 3, 29]], dtype=int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm_results = confusion_matrix(y_test,y_predict)\n",
    "cm_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"The True Positive of Number of People Purchased is {}\".format(cm_results[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the Testing dataset Result\n",
    "# Import the Color Map class\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "# Training Dataset\n",
    "X_set,y_set = X_train, y_train\n",
    "\n",
    "# set the plot figsize\n",
    "plt.figure(figsize=(20,10))\n",
    "\n",
    "\n",
    "# Prepare the grid by collect the pixel points and put it in the frame\n",
    "X1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, stop = X_set[:, 0].max() + 1, step = 0.01),\n",
    "                     np.arange(start = X_set[:, 1].min() - 1, stop = X_set[:, 1].max() + 1, step = 0.01))\n",
    "\n",
    "\n",
    "# Contour function will create a linear line between red and green\n",
    "# Use predict function to predict the 0 or 1.If predict as 0 it will colorised as red or else it will green\n",
    "plt.contourf(X1,X2, classifier.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape),\n",
    "            alpha = 0.75, cmap = ListedColormap(('red','green')))\n",
    "\n",
    "# Create a limit of estimate salary\n",
    "plt.ylim(X1.min(), X1.max())\n",
    "plt.ylim(X2.min(), X2.max())\n",
    "\n",
    "\n",
    "# Create a scatter plot\n",
    "for i,j in enumerate(np.unique(y_set)):\n",
    "    plt.scatter(X_set[y_set ==j, 0] , X_set[y_set ==j, 1], c = ListedColormap(('red','green'))(i), label = j)\n",
    "    \n",
    "plt.title(\"SVM - Linear - Training Set\")\n",
    "plt.xlabel(\"Age\")\n",
    "plt.xlabel(\"Estimated Salary\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the Testing dataset Result\n",
    "# Import the Color Map class\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "# Training Dataset\n",
    "X_set,y_set = X_test, y_test\n",
    "\n",
    "# set the plot figsize\n",
    "plt.figure(figsize=(20,10))\n",
    "\n",
    "\n",
    "# Prepare the grid by collect the pixel points and put it in the frame\n",
    "X1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, stop = X_set[:, 0].max() + 1, step = 0.01),\n",
    "                     np.arange(start = X_set[:, 1].min() - 1, stop = X_set[:, 1].max() + 1, step = 0.01))\n",
    "\n",
    "\n",
    "# Contour function will create a linear line between red and green\n",
    "# Use predict function to predict the 0 or 1.If predict as 0 it will colorised as red or else it will green\n",
    "plt.contourf(X1,X2, classifier.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape),\n",
    "            alpha = 0.75, cmap = ListedColormap(('red','green')))\n",
    "\n",
    "# Create a limit of estimate salary\n",
    "plt.ylim(X1.min(), X1.max())\n",
    "plt.ylim(X2.min(), X2.max())\n",
    "\n",
    "\n",
    "# Create a scatter plot\n",
    "for i,j in enumerate(np.unique(y_set)):\n",
    "    plt.scatter(X_set[y_set ==j, 0] , X_set[y_set ==j, 1], c = ListedColormap(('red','green'))(i), label = j)\n",
    "    \n",
    "plt.title(\"SVM - Linear - Testing Set\")\n",
    "plt.xlabel(\"Age\")\n",
    "plt.xlabel(\"Estimated Salary\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (cm_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#https://www.kaggle.com/grfiv4/plot-a-confusion-matrix\n",
    "import itertools\n",
    "def plot_confusion_matrix(cm,\n",
    "                          target_names,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=None,\n",
    "                          normalize=True):\n",
    "\n",
    "    accuracy = np.trace(cm) / float(np.sum(cm))\n",
    "    misclass = 1 - accuracy\n",
    "\n",
    "    if cmap is None:\n",
    "        cmap = plt.get_cmap('Blues')\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "\n",
    "    if target_names is not None:\n",
    "        tick_marks = np.arange(len(target_names))\n",
    "        plt.xticks(tick_marks, target_names, rotation=45)\n",
    "        plt.yticks(tick_marks, target_names)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "\n",
    "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        if normalize:\n",
    "            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "        else:\n",
    "            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(cm           = cm_results, \n",
    "                      normalize    = False,\n",
    "                      target_names = ['Purchased', 'Not_Purchased'],\n",
    "                      title        = \"Confusion Matrix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicted Correctly\n",
    "\n",
    "print (\"[TP] - Predicted - True Positive of Number of People Purchased is {}\".format(cm_results[0][0]))\n",
    "print (\"[TN] - Predicted - True Negative of Number of People Not-Purchased is {}\".format(cm_results[1][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicted Wrongly\n",
    "print (\"[FN] - Predicted - False Negative of Number of People Purchased is {}\".format(cm_results[0][1]))\n",
    "print (\"[FP] - Predicted - False Positive of Number of People Not-Purchased is {}\".format(cm_results[1][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Formula for Understanding Model Performance\n",
    "\n",
    "# Accuracy = (TN+TP)/(TN+FP+FN+TP)\n",
    "# Precision = TP/(FP+TP)\n",
    "# Recall = Sensitivity = TP / (TP+FN)\n",
    "# Specificity = TN / (TN+FP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# http://scikit-learn.org/stable/auto_examples/model_selection/plot_precision_recall.html#sphx-glr-auto-examples-model-selection-plot-precision-recall-py\n",
    "# Precision\n",
    "#Precision (P) is defined as the number of true positives (T_p) over the number of true positives plus the \n",
    "#number of false positives (F_p).\n",
    "\n",
    "## Accuracy = (TN+TP)/(TN+FP+FN+TP)\n",
    "from sklearn.metrics import precision_score\n",
    "accuracy_score = precision_score(y_test, y_predict)\n",
    "print('Accuracy Score: {0:0.2f}'.format(accuracy_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Recall = Sensitivity = TP / (TP+FN)\n",
    "from sklearn.metrics import recall_score\n",
    "recall_value = recall_score(y_test, y_predict)\n",
    "print('Recall Score: {0:0.2f}'.format(recall_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate F1-Score\n",
    "from sklearn.metrics import f1_score\n",
    "fscore_value = f1_score(y_test, y_predict)\n",
    "print('F-Score: {0:0.2f}'.format(fscore_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import average_precision_score\n",
    "average_precision = average_precision_score(y_test, y_predict)\n",
    "\n",
    "print('Average precision-recall score: {0:0.2f}'.format(average_precision))\n",
    "\n",
    "from sklearn.metrics import recall_score\n",
    "recall_value = recall_score(y_test, y_predict)\n",
    "print('Average recall score: {0:0.2f}'.format(recall_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
